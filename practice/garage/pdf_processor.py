"""
Enhanced PDF OCR Processing System
ê°œì„ ëœ PDF OCR ì²˜ë¦¬ ì‹œìŠ¤í…œ - í´ë˜ìŠ¤ ê¸°ë°˜ ì•„í‚¤í…ì²˜
"""

import asyncio
import hashlib
import json
import logging
import time
from abc import ABC, abstractmethod
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any, Protocol
from io import BytesIO

import pytesseract
from PIL import Image, ImageOps
from pdf2image import convert_from_path
from pypdf import PdfReader, PdfWriter
from tqdm import tqdm

try:
    from langdetect import detect as lang_detect
except ImportError:
    lang_detect = None


class ProcessingStatus(Enum):
    """ì²˜ë¦¬ ìƒíƒœ ì—´ê±°í˜•"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"


@dataclass
class ProcessingConfig:
    """ì²˜ë¦¬ ì„¤ì • í´ë˜ìŠ¤"""
    dpi: int = 300
    language: str = "auto"
    confidence_threshold: int = 50
    workers: int = 4
    auto_dpi: bool = False
    save_json: bool = False
    resume: bool = True
    keep_checkpoints: bool = False
    cache_enabled: bool = True
    cache_ttl: int = 86400  # 24ì‹œê°„
    preprocessing_enabled: bool = True
    binarization_threshold: int = 140


@dataclass
class WordData:
    """OCR ë‹¨ì–´ ë°ì´í„°"""
    text: str
    confidence: int
    bbox: Dict[str, int]
    page_number: int


@dataclass
class PageResult:
    """í˜ì´ì§€ ì²˜ë¦¬ ê²°ê³¼"""
    page_number: int
    status: ProcessingStatus
    words: List[WordData] = field(default_factory=list)
    language: str = "eng"
    processing_time: float = 0.0
    error_message: Optional[str] = None


@dataclass
class DocumentResult:
    """ë¬¸ì„œ ì²˜ë¦¬ ê²°ê³¼"""
    file_path: Path
    total_pages: int
    processed_pages: int
    status: ProcessingStatus
    pages: List[PageResult] = field(default_factory=list)
    processing_time: float = 0.0
    config: Optional[ProcessingConfig] = None


class CacheProtocol(Protocol):
    """ìºì‹œ ì¸í„°í˜ì´ìŠ¤"""
    def get(self, key: str) -> Optional[Any]: ...
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None: ...
    def exists(self, key: str) -> bool: ...
    def clear(self) -> None: ...


class MemoryCache:
    """ë©”ëª¨ë¦¬ ê¸°ë°˜ ìºì‹œ êµ¬í˜„"""
    
    def __init__(self):
        self._cache: Dict[str, Tuple[Any, float]] = {}
    
    def get(self, key: str) -> Optional[Any]:
        if key in self._cache:
            value, expires = self._cache[key]
            if expires == 0 or time.time() < expires:
                return value
            else:
                del self._cache[key]
        return None
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        expires = time.time() + ttl if ttl else 0
        self._cache[key] = (value, expires)
    
    def exists(self, key: str) -> bool:
        return self.get(key) is not None
    
    def clear(self) -> None:
        self._cache.clear()


class ImagePreprocessor:
    """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: ProcessingConfig):
        self.config = config
    
    def preprocess(self, image: Image.Image) -> Image.Image:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ìˆ˜í–‰"""
        if not self.config.preprocessing_enabled:
            return image
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if image.mode != 'L':
            image = ImageOps.grayscale(image)
        
        # ìë™ ëŒ€ë¹„ ì¡°ì •
        image = ImageOps.autocontrast(image)
        
        # ì´ì§„í™”
        image = image.point(
            lambda x: 0 if x < self.config.binarization_threshold else 255, 
            "1"
        )
        
        return image


class LanguageDetector:
    """ì–¸ì–´ ê°ì§€ í´ë˜ìŠ¤"""
    
    @staticmethod
    def detect_language(image: Image.Image, fallback: str = "eng") -> str:
        """ì´ë¯¸ì§€ì—ì„œ ì–¸ì–´ ê°ì§€"""
        if lang_detect is None:
            return fallback
        
        try:
            temp_text = pytesseract.image_to_string(image, lang=fallback)
            if temp_text.strip():
                detected = lang_detect(temp_text)
                # ì–¸ì–´ ì½”ë“œ ë§¤í•‘ (í•„ìš”ì‹œ í™•ì¥)
                lang_mapping = {
                    'ko': 'kor',
                    'en': 'eng',
                    'ja': 'jpn',
                    'zh': 'chi_sim'
                }
                return lang_mapping.get(detected, detected)
            return fallback
        except Exception:
            return fallback


class DPIOptimizer:
    """DPI ìµœì í™” í´ë˜ìŠ¤"""
    
    def __init__(self, config: ProcessingConfig):
        self.config = config
        self.candidate_dpis = [200, 300, 400, 500]
    
    def find_optimal_dpi(self, pdf_path: Path, sample_pages: int = 2) -> int:
        """ìµœì  DPI ì°¾ê¸°"""
        if not self.config.auto_dpi:
            return self.config.dpi
        
        best_dpi = self.candidate_dpis[0]
        best_score = -1
        total_pages = self._get_pdf_page_count(pdf_path)
        
        with tqdm(
            total=min(sample_pages, total_pages) * len(self.candidate_dpis),
            desc="ğŸ” DPI ìµœì í™”",
            unit="test"
        ) as pbar:
            for page_num in range(1, min(sample_pages + 1, total_pages + 1)):
                for dpi in self.candidate_dpis:
                    try:
                        score = self._evaluate_dpi(pdf_path, page_num, dpi)
                        if score > best_score:
                            best_score = score
                            best_dpi = dpi
                    except Exception:
                        pass
                    finally:
                        pbar.update(1)
        
        return best_dpi
    
    def _evaluate_dpi(self, pdf_path: Path, page_num: int, dpi: int) -> int:
        """íŠ¹ì • DPIë¡œ í˜ì´ì§€ í‰ê°€"""
        images = convert_from_path(
            str(pdf_path), 
            dpi=dpi, 
            first_page=page_num, 
            last_page=page_num
        )
        
        if not images:
            return 0
        
        preprocessor = ImagePreprocessor(self.config)
        processed_image = preprocessor.preprocess(images[0])
        
        data = pytesseract.image_to_data(
            processed_image, 
            output_type=pytesseract.Output.DICT
        )
        
        # ì‹ ë¢°ë„ ë†’ì€ ë‹¨ì–´ ìˆ˜ ë°˜í™˜
        return sum(
            1 for i, conf in enumerate(data.get('conf', []))
            if data.get('text', [None] * len(data.get('conf', [])))[i] and 
            int(conf) >= self.config.confidence_threshold
        )
    
    @staticmethod
    def _get_pdf_page_count(pdf_path: Path) -> int:
        """PDF í˜ì´ì§€ ìˆ˜ ë°˜í™˜"""
        return len(PdfReader(str(pdf_path)).pages)


class CheckpointManager:
    """ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, base_dir: Path):
        self.base_dir = base_dir
        self.checkpoint_dir = base_dir / ".checkpoints"
    
    def create_checkpoint_dir(self, document_id: str) -> Path:
        """ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±"""
        checkpoint_path = self.checkpoint_dir / document_id
        checkpoint_path.mkdir(parents=True, exist_ok=True)
        return checkpoint_path
    
    def save_manifest(self, checkpoint_path: Path, manifest: Dict) -> None:
        """ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì €ì¥"""
        manifest_file = checkpoint_path / "manifest.json"
        manifest_file.write_text(
            json.dumps(manifest, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
    
    def load_manifest(self, checkpoint_path: Path) -> Optional[Dict]:
        """ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¡œë“œ"""
        manifest_file = checkpoint_path / "manifest.json"
        if manifest_file.exists():
            return json.loads(manifest_file.read_text(encoding="utf-8"))
        return None
    
    def save_page_result(self, checkpoint_path: Path, page_result: PageResult, pdf_bytes: bytes) -> None:
        """í˜ì´ì§€ ê²°ê³¼ ì €ì¥"""
        # PDF ì €ì¥
        pdf_file = checkpoint_path / f"page_{page_result.page_number:05d}.pdf"
        pdf_file.write_bytes(pdf_bytes)
        
        # JSON ì €ì¥ (ì„¤ì •ì— ë”°ë¼)
        json_file = checkpoint_path / f"page_{page_result.page_number:05d}.json"
        page_data = {
            "page": page_result.page_number,
            "status": page_result.status.value,
            "language": page_result.language,
            "processing_time": page_result.processing_time,
            "words": [
                {
                    "text": word.text,
                    "confidence": word.confidence,
                    "bbox": word.bbox
                }
                for word in page_result.words
            ]
        }
        json_file.write_text(
            json.dumps(page_data, ensure_ascii=False, indent=2),
            encoding="utf-8"
        )
    
    def cleanup_checkpoints(self, checkpoint_path: Path) -> None:
        """ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬"""
        for file in checkpoint_path.glob("*"):
            try:
                file.unlink()
            except Exception:
                pass
        try:
            checkpoint_path.rmdir()
        except Exception:
            pass


class OCRProcessor:
    """OCR ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, config: ProcessingConfig, cache: Optional[CacheProtocol] = None):
        self.config = config
        self.cache = cache or MemoryCache()
        self.preprocessor = ImagePreprocessor(config)
        self.language_detector = LanguageDetector()
    
    def process_image(self, image: Image.Image, page_number: int, language: str) -> PageResult:
        """ë‹¨ì¼ ì´ë¯¸ì§€ OCR ì²˜ë¦¬"""
        start_time = time.time()
        
        try:
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = self._generate_cache_key(image, language)
            
            if self.config.cache_enabled and self.cache.exists(cache_key):
                cached_result = self.cache.get(cache_key)
                if cached_result:
                    cached_result.page_number = page_number
                    return cached_result
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            processed_image = self.preprocessor.preprocess(image)
            
            # ì–¸ì–´ ê°ì§€
            if language == "auto":
                language = self.language_detector.detect_language(processed_image)
            
            # OCR ìˆ˜í–‰
            words = self._extract_words(processed_image, language, page_number)
            
            result = PageResult(
                page_number=page_number,
                status=ProcessingStatus.COMPLETED,
                words=words,
                language=language,
                processing_time=time.time() - start_time
            )
            
            # ìºì‹œ ì €ì¥
            if self.config.cache_enabled:
                self.cache.set(cache_key, result, self.config.cache_ttl)
            
            return result
            
        except Exception as e:
            return PageResult(
                page_number=page_number,
                status=ProcessingStatus.FAILED,
                error_message=str(e),
                processing_time=time.time() - start_time
            )
    
    def _extract_words(self, image: Image.Image, language: str, page_number: int) -> List[WordData]:
        """ì´ë¯¸ì§€ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ"""
        data = pytesseract.image_to_data(
            image, 
            lang=language, 
            output_type=pytesseract.Output.DICT
        )
        
        words = []
        for i in range(len(data.get('text', []))):
            text = (data['text'][i] or "").strip()
            try:
                confidence = int(float(data['conf'][i]))
            except (ValueError, TypeError):
                confidence = -1
            
            if text and confidence >= self.config.confidence_threshold:
                words.append(WordData(
                    text=text,
                    confidence=confidence,
                    bbox={
                        "x": int(data['left'][i]),
                        "y": int(data['top'][i]),
                        "w": int(data['width'][i]),
                        "h": int(data['height'][i]),
                    },
                    page_number=page_number
                ))
        
        return words
    
    def _generate_cache_key(self, image: Image.Image, language: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        # ì´ë¯¸ì§€ í•´ì‹œ + ì„¤ì • í•´ì‹œ
        image_bytes = BytesIO()
        image.save(image_bytes, format='PNG')
        image_hash = hashlib.md5(image_bytes.getvalue()).hexdigest()
        
        config_str = f"{language}_{self.config.confidence_threshold}_{self.config.binarization_threshold}"
        config_hash = hashlib.md5(config_str.encode()).hexdigest()
        
        return f"{image_hash}_{config_hash}"
    
    def create_searchable_pdf(self, image: Image.Image, language: str) -> bytes:
        """ê²€ìƒ‰ ê°€ëŠ¥í•œ PDF ìƒì„±"""
        processed_image = self.preprocessor.preprocess(image)
        return pytesseract.image_to_pdf_or_hocr(
            processed_image, 
            lang=language, 
            extension="pdf"
        )


class PDFProcessor:
    """PDF ì²˜ë¦¬ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self, config: ProcessingConfig, cache: Optional[CacheProtocol] = None):
        self.config = config
        self.cache = cache or MemoryCache()
        self.ocr_processor = OCRProcessor(config, cache)
        self.dpi_optimizer = DPIOptimizer(config)
        self.checkpoint_manager = CheckpointManager(Path("./output"))
        self.logger = self._setup_logger()
    
    async def process_document(self, file_path: Path, output_dir: Path) -> DocumentResult:
        """ë¬¸ì„œ ì²˜ë¦¬ (ë¹„ë™ê¸°)"""
        start_time = time.time()
        
        try:
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ë¬¸ì„œ ID ìƒì„±
            document_id = file_path.stem
            
            # ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
            checkpoint_path = self.checkpoint_manager.create_checkpoint_dir(document_id)
            
            # ìµœì  DPI ê²°ì •
            optimal_dpi = self.dpi_optimizer.find_optimal_dpi(file_path)
            self.logger.info(f"ìµœì  DPI ì„ íƒë¨: {optimal_dpi}")
            
            # PDF ì²˜ë¦¬
            result = await self._process_pdf_async(
                file_path, 
                output_dir, 
                checkpoint_path, 
                optimal_dpi
            )
            
            result.processing_time = time.time() - start_time
            result.config = self.config
            
            return result
            
        except Exception as e:
            self.logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return DocumentResult(
                file_path=file_path,
                total_pages=0,
                processed_pages=0,
                status=ProcessingStatus.FAILED,
                processing_time=time.time() - start_time
            )
    
    async def _process_pdf_async(self, 
                                 pdf_path: Path, 
                                 output_dir: Path, 
                                 checkpoint_path: Path, 
                                 dpi: int) -> DocumentResult:
        """ë¹„ë™ê¸° PDF ì²˜ë¦¬"""
        
        total_pages = self.dpi_optimizer._get_pdf_page_count(pdf_path)
        
        # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë¡œë“œ/ìƒì„±
        manifest = self.checkpoint_manager.load_manifest(checkpoint_path)
        if not manifest:
            manifest = {
                "file": pdf_path.name,
                "dpi": dpi,
                "total_pages": total_pages,
                "completed_pages": [],
                "config": self.config.__dict__
            }
        
        completed_pages = set(manifest.get("completed_pages", []))
        
        # ì²˜ë¦¬í•  í˜ì´ì§€ ê²°ì •
        pending_pages = [
            i for i in range(1, total_pages + 1) 
            if i not in completed_pages
        ]
        
        if not pending_pages:
            self.logger.info("ëª¨ë“  í˜ì´ì§€ê°€ ì´ë¯¸ ì²˜ë¦¬ë¨")
            return await self._finalize_document(pdf_path, checkpoint_path, output_dir, manifest)
        
        # ë³‘ë ¬ ì²˜ë¦¬
        page_results = await self._process_pages_parallel(
            pdf_path, 
            pending_pages, 
            dpi, 
            checkpoint_path
        )
        
        # ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        for result in page_results:
            if result.status == ProcessingStatus.COMPLETED:
                completed_pages.add(result.page_number)
        
        manifest["completed_pages"] = sorted(list(completed_pages))
        self.checkpoint_manager.save_manifest(checkpoint_path, manifest)
        
        # ìµœì¢… ë¬¸ì„œ ìƒì„±
        return await self._finalize_document(pdf_path, checkpoint_path, output_dir, manifest)
    
    async def _process_pages_parallel(self, 
                                      pdf_path: Path, 
                                      page_numbers: List[int], 
                                      dpi: int, 
                                      checkpoint_path: Path) -> List[PageResult]:
        """í˜ì´ì§€ ë³‘ë ¬ ì²˜ë¦¬"""
        
        loop = asyncio.get_event_loop()
        results = []
        
        with ProcessPoolExecutor(max_workers=self.config.workers) as executor:
            tasks = []
            for page_num in page_numbers:
                task = loop.run_in_executor(
                    executor,
                    self._process_single_page,
                    pdf_path,
                    page_num,
                    dpi
                )
                tasks.append(task)
            
            # ì§„í–‰ë¥  í‘œì‹œ
            with tqdm(total=len(tasks), desc=f"ğŸ“„ {pdf_path.name}", unit="page") as pbar:
                for completed_task in asyncio.as_completed(tasks):
                    result = await completed_task
                    results.append(result)
                    
                    # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
                    if result.status == ProcessingStatus.COMPLETED:
                        # PDF ë°”ì´íŠ¸ ìƒì„±
                        images = convert_from_path(
                            str(pdf_path), 
                            dpi=dpi, 
                            first_page=result.page_number, 
                            last_page=result.page_number
                        )
                        if images:
                            pdf_bytes = self.ocr_processor.create_searchable_pdf(
                                images[0], 
                                result.language
                            )
                            self.checkpoint_manager.save_page_result(
                                checkpoint_path, 
                                result, 
                                pdf_bytes
                            )
                    
                    pbar.update(1)
        
        return results
    
    def _process_single_page(self, pdf_path: Path, page_number: int, dpi: int) -> PageResult:
        """ë‹¨ì¼ í˜ì´ì§€ ì²˜ë¦¬ (ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ìš©)"""
        try:
            # PDFë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
            images = convert_from_path(
                str(pdf_path), 
                dpi=dpi, 
                first_page=page_number, 
                last_page=page_number
            )
            
            if not images:
                return PageResult(
                    page_number=page_number,
                    status=ProcessingStatus.FAILED,
                    error_message="ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨"
                )
            
            # OCR ì²˜ë¦¬
            return self.ocr_processor.process_image(
                images[0], 
                page_number, 
                self.config.language
            )
            
        except Exception as e:
            return PageResult(
                page_number=page_number,
                status=ProcessingStatus.FAILED,
                error_message=str(e)
            )
    
    async def _finalize_document(self, 
                                 pdf_path: Path, 
                                 checkpoint_path: Path, 
                                 output_dir: Path, 
                                 manifest: Dict) -> DocumentResult:
        """ë¬¸ì„œ ìµœì¢…í™”"""
        
        # PDF ë³‘í•©
        output_pdf = output_dir / f"{pdf_path.stem}_searchable.pdf"
        await self._merge_pdfs(checkpoint_path, output_pdf)
        
        # JSON ë³‘í•© (ì˜µì…˜)
        if self.config.save_json:
            await self._merge_json_files(checkpoint_path, output_pdf.with_suffix(".json"))
        
        # ì²´í¬í¬ì¸íŠ¸ ì •ë¦¬
        if not self.config.keep_checkpoints:
            self.checkpoint_manager.cleanup_checkpoints(checkpoint_path)
        
        # ê²°ê³¼ ìƒì„±
        total_pages = manifest["total_pages"]
        completed_pages = len(manifest.get("completed_pages", []))
        
        return DocumentResult(
            file_path=pdf_path,
            total_pages=total_pages,
            processed_pages=completed_pages,
            status=ProcessingStatus.COMPLETED if completed_pages == total_pages else ProcessingStatus.FAILED
        )
    
    async def _merge_pdfs(self, checkpoint_path: Path, output_path: Path) -> None:
        """PDF íŒŒì¼ë“¤ ë³‘í•©"""
        writer = PdfWriter()
        pdf_files = sorted(checkpoint_path.glob("page_*.pdf"))
        
        for pdf_file in pdf_files:
            reader = PdfReader(str(pdf_file))
            for page in reader.pages:
                writer.add_page(page)
        
        # ë¹„ë™ê¸°ë¡œ ì“°ê¸°
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None, 
            lambda: output_path.write_bytes(self._write_pdf_to_bytes(writer))
        )
    
    async def _merge_json_files(self, checkpoint_path: Path, output_path: Path) -> None:
        """JSON íŒŒì¼ë“¤ ë³‘í•©"""
        merged_data = {
            "type": "pdf",
            "pages": []
        }
        
        json_files = sorted(checkpoint_path.glob("page_*.json"))
        for json_file in json_files:
            page_data = json.loads(json_file.read_text(encoding="utf-8"))
            merged_data["pages"].append(page_data)
        
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None,
            lambda: output_path.write_text(
                json.dumps(merged_data, ensure_ascii=False, indent=2),
                encoding="utf-8"
            )
        )
    
    def _write_pdf_to_bytes(self, writer: PdfWriter) -> bytes:
        """PDF Writerë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
        bio = BytesIO()
        writer.write(bio)
        return bio.getvalue()
    
    def _setup_logger(self) -> logging.Logger:
        """ë¡œê±° ì„¤ì •"""
        logger = logging.getLogger(__name__)
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s | %(levelname)s | %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger


# íŒ©í† ë¦¬ íŒ¨í„´
class ProcessorFactory:
    """í”„ë¡œì„¸ì„œ íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_processor(config: ProcessingConfig, cache: Optional[CacheProtocol] = None) -> PDFProcessor:
        """í”„ë¡œì„¸ì„œ ìƒì„±"""
        return PDFProcessor(config, cache)
    
    @staticmethod
    def create_config(**kwargs) -> ProcessingConfig:
        """ì„¤ì • ìƒì„±"""
        return ProcessingConfig(**kwargs)


# ì‚¬ìš© ì˜ˆì‹œ í•¨ìˆ˜
async def process_documents(file_paths: List[Path], output_dir: Path, config: ProcessingConfig) -> List[DocumentResult]:
    """ì—¬ëŸ¬ ë¬¸ì„œ ì²˜ë¦¬"""
    processor = ProcessorFactory.create_processor(config)
    
    tasks = [
        processor.process_document(file_path, output_dir)
        for file_path in file_paths
    ]
    
    results = []
    for completed_task in asyncio.as_completed(tasks):
        result = await completed_task
        results.append(result)
    
    return results


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    async def main():
        config = ProcessorFactory.create_config(
            dpi=300,
            auto_dpi=True,
            workers=4,
            save_json=True
        )
        
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì˜ˆì‹œ
        # processor = ProcessorFactory.create_processor(config)
        # result = await processor.process_document(
        #     Path("input.pdf"),
        #     Path("./output")
        # )
        # print(f"ì²˜ë¦¬ ì™„ë£Œ: {result.status}")
    
    # asyncio.run(main())