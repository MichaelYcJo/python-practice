from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
import textwrap
import warnings

# ê²½ê³  ì œê±°
warnings.filterwarnings("ignore")

# ìš”ì•½ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
def load_summarizer(model_name="t5-small"):
    print(f"ğŸ“¦ ëª¨ë¸ ë¡œë”©: {model_name}")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    return pipeline("summarization", model=model, tokenizer=tokenizer)

# í…ìŠ¤íŠ¸ ìš”ì•½ í•¨ìˆ˜
def summarize_text(text: str, model_name="t5-small", min_length=30, max_length=130):
    if not text or not isinstance(text, str):
        raise ValueError("ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

    print("\nğŸ“ ìš”ì•½ ëŒ€ìƒ í…ìŠ¤íŠ¸ ì¼ë¶€:")
    print(textwrap.shorten(text.strip(), width=300, placeholder="...") + "\n")

    summarizer = load_summarizer(model_name)
    print("ğŸ§  ìš”ì•½ ì¤‘...")
    summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)
    return summary[0]["summary_text"]

# ì˜ˆì‹œ ì‹¤í–‰
if __name__ == "__main__":
    sample_text = """
    ì¸ê³µì§€ëŠ¥(AI)ì€ ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ê³¼ ìœ ì‚¬í•œ ë°©ì‹ìœ¼ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„ëœ ê¸°ìˆ ì„ ì˜ë¯¸í•œë‹¤.
    AI ê¸°ìˆ ì€ ìŒì„± ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬, ì´ë¯¸ì§€ ë¶„ì„, ì˜ì‚¬ ê²°ì • ë“±ì„ í¬í•¨í•œë‹¤.
    íŠ¹íˆ ìµœê·¼ì—ëŠ” ìƒì„±í˜• AI ê¸°ìˆ ì˜ ë°œì „ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±, ì´ë¯¸ì§€ ìƒì„±, ìŒì•… ì‘ê³¡ ë“± ì°½ì˜ì ì¸ ì˜ì—­ê¹Œì§€ í™œìš© ë²”ìœ„ê°€ í™•ì¥ë˜ê³  ìˆë‹¤.
    ë§ì€ ê¸°ì—…ë“¤ì´ AI ê¸°ìˆ ì„ í™œìš©í•´ ë¹„ì¦ˆë‹ˆìŠ¤ íš¨ìœ¨ì„ ë†’ì´ê³  ìˆìœ¼ë©°, ê´€ë ¨ ì‹œì¥ë„ ë¹ ë¥´ê²Œ ì„±ì¥í•˜ê³  ìˆë‹¤.
    """

    summary = summarize_text(sample_text, model_name="t5-small")
    print("âœ… ìš”ì•½ ê²°ê³¼:")
    print(summary)