import os
import re
from collections import Counter


def clean_text(text):
    """ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±° ë° ì†Œë¬¸ì ë³€í™˜"""
    text = re.sub(r"\n+", " ", text)  # ì¤„ë°”ê¿ˆ ì œê±°
    text = re.sub(r"[^ã„±-ã…ê°€-í£a-zA-Z0-9\s\.]", "", text)  # íŠ¹ìˆ˜ê¸°í˜¸ ì œê±°
    return text.lower()


def split_sentences(text):
    """ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ ê¸°ì¤€)"""
    return [sentence.strip() for sentence in text.split(".") if sentence.strip()]


def get_keywords(text, top_n=5):
    """ê°€ì¥ ë§ì´ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ top_n ë°˜í™˜"""
    words = text.split()
    stopwords = {
        "the",
        "is",
        "a",
        "an",
        "in",
        "to",
        "of",
        "and",
        "on",
        "at",
        "for",
        "with",
        "as",
        "by",
        "was",
        "are",
    }
    words = [word for word in words if word not in stopwords and len(word) > 2]
    return [word for word, _ in Counter(words).most_common(top_n)]


def extract_summary(text, num_sentences=2):
    """í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ"""
    cleaned = clean_text(text)
    keywords = get_keywords(cleaned)
    sentences = split_sentences(text)

    # í‚¤ì›Œë“œ í¬í•¨ëœ ë¬¸ì¥ë§Œ ì¶”ì¶œ
    ranked_sentences = [s for s in sentences if any(k in s.lower() for k in keywords)]

    return (
        ranked_sentences[:num_sentences]
        if ranked_sentences
        else sentences[:num_sentences]
    )


def main():
    """í…ìŠ¤íŠ¸ ìš”ì•½ ì‹¤í–‰"""
    print("ğŸ“„ ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ .txt íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    path_or_text = input("ğŸ“ í…ìŠ¤íŠ¸ ë˜ëŠ” íŒŒì¼ ê²½ë¡œ: ").strip()

    if os.path.exists(path_or_text) and path_or_text.endswith(".txt"):
        with open(path_or_text, encoding="utf-8") as f:
            text = f.read()
    else:
        text = path_or_text

    summary = extract_summary(text)

    print("\nğŸ“Œ ìš”ì•½ ê²°ê³¼:")
    for idx, sentence in enumerate(summary, 1):
        print(f"{idx}. {sentence.strip()}")


# ì‹¤í–‰
main()
