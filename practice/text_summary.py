import os
import re
import math
from collections import defaultdict, Counter

"""
TF-IDFê¸°ë°˜ -> ë‹¨ìˆœí‚¤ì›Œë“œ íšŸìˆ˜ ëŒ€ì‹  ë¬¸ì¥ ì¤‘ìš”ë„ ê³ ë ¤
ë¬¸ì¥ë³„ ì ìˆ˜ë¥¼ í†µí•œ ìš”ì•½
"""


def clean_text(text):
    """ê¸°í˜¸ ì œê±° ë° ì†Œë¬¸ì ë³€í™˜"""
    text = re.sub(r"\n+", " ", text)
    text = re.sub(r"[^ã„±-ã…ê°€-í£a-zA-Z0-9\s\.]", "", text)
    return text.lower()


def split_sentences(text):
    """ê°„ë‹¨í•œ ë¬¸ì¥ ë¶„ë¦¬"""
    return [s.strip() for s in re.split(r"\.\s*", text) if len(s.strip()) > 10]


def tokenize(text):
    stopwords = {
        "the",
        "is",
        "a",
        "an",
        "in",
        "to",
        "of",
        "and",
        "on",
        "at",
        "for",
        "with",
        "as",
        "by",
        "was",
        "are",
    }
    words = re.findall(r"\w+", text.lower())
    return [w for w in words if w not in stopwords and len(w) > 2]


def compute_tf(sent_tokens):
    """ë¬¸ì¥ë³„ TF ê³„ì‚°"""
    return [Counter(tokenize(sent)) for sent in sent_tokens]


def compute_idf(sent_tokens):
    """IDF ê³„ì‚°"""
    N = len(sent_tokens)
    idf = defaultdict(lambda: 0)
    for tokens in sent_tokens:
        for word in set(tokenize(tokens)):
            idf[word] += 1
    for word in idf:
        idf[word] = math.log(N / (1 + idf[word]))
    return idf


def score_sentences(sentences, tf_list, idf):
    scores = []
    for i, tf in enumerate(tf_list):
        score = 0
        for word in tf:
            score += tf[word] * idf.get(word, 0)
        scores.append((score, sentences[i]))
    return sorted(scores, key=lambda x: x[0], reverse=True)


def extract_summary(text, top_n=3):
    sentences = split_sentences(text)
    if not sentences:
        return []

    tf = compute_tf(sentences)
    idf = compute_idf(sentences)
    ranked = score_sentences(sentences, tf, idf)

    summary = [sent for _, sent in ranked[:top_n]]
    return summary


def main():
    print("ğŸ“„ ìš”ì•½í•  í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ .txt íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    path_or_text = input("ğŸ“ í…ìŠ¤íŠ¸ ë˜ëŠ” íŒŒì¼ ê²½ë¡œ: ").strip()

    if os.path.exists(path_or_text) and path_or_text.endswith(".txt"):
        with open(path_or_text, encoding="utf-8") as f:
            text = f.read()
    else:
        text = path_or_text

    summary = extract_summary(text)

    print("\nğŸ“Œ ìš”ì•½ ê²°ê³¼:")
    for i, sentence in enumerate(summary, 1):
        print(f"{i}. {sentence.strip()}")


if __name__ == "__main__":
    main()
