# pip install diffusers transformers accelerate safetensors
# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ~/.cache/huggingface/hub

import torch
from diffusers import StableDiffusionPipeline
import gc
import warnings
from datetime import datetime
import os
import logging
from typing import Optional, Tuple

warnings.filterwarnings("ignore", message="resource_tracker: There appear to be .*")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

SAVE_DIR = "generated_images"
os.makedirs(SAVE_DIR, exist_ok=True)

class ImageGenerationError(Exception):
    """ì´ë¯¸ì§€ ìƒì„± ì¤‘ ë°œìƒí•˜ëŠ” ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì»¤ìŠ¤í…€ ì˜ˆì™¸"""
    pass

def load_pipeline() -> StableDiffusionPipeline:
    """Stable Diffusion íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    if not hasattr(load_pipeline, "pipe"):
        try:
            logger.info("â³ ëª¨ë¸ ë¡œë”© ì¤‘...")
            load_pipeline.pipe = StableDiffusionPipeline.from_pretrained(
                "runwayml/stable-diffusion-v1-5",
                torch_dtype=torch.float16,
                safety_checker=None,  # ì•ˆì „ì„± ê²€ì‚¬ ë¹„í™œì„±í™”ë¡œ ì„±ëŠ¥ í–¥ìƒ
            ).to("mps")
            logger.info("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise ImageGenerationError(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
    return load_pipeline.pipe

def generate_image(
    prompt: str,
    save_path: str,
    height: int = 512,
    width: int = 512,
    num_inference_steps: int = 50,
    guidance_scale: float = 7.5
) -> None:
    """ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        pipe = load_pipeline()
        logger.info(f"ğŸ¨ '{prompt}' ì— ëŒ€í•œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")

        image = pipe(
            prompt,
            height=height,
            width=width,
            num_inference_steps=num_inference_steps,
            guidance_scale=guidance_scale
        ).images[0]
        
        image.save(save_path)
        logger.info(f"âœ… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}")
        
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise ImageGenerationError(f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def cleanup_resources() -> None:
    """ë©”ëª¨ë¦¬ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
    try:
        if hasattr(load_pipeline, "pipe"):
            del load_pipeline.pipe
        torch.cuda.empty_cache() if torch.cuda.is_available() else None
        gc.collect()
        logger.info("ğŸ§¹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        logger.error(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

def main():
    try:
        prompt = input("ğŸ“ ì´ë¯¸ì§€ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if not prompt:
            raise ValueError("í”„ë¡¬í”„íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"image_{timestamp}.png"
        save_path = os.path.join(SAVE_DIR, filename)

        generate_image(prompt, save_path)
        
    except Exception as e:
        logger.error(f"í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        cleanup_resources()

if __name__ == "__main__":
    main()
