from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained("prithivida/grammar_error_correcter_v1")
model = AutoModelForSeq2SeqLM.from_pretrained("prithivida/grammar_error_correcter_v1")

def correct_sentence(text: str) -> str:
    """ë‹¨ì¼ ë¬¸ì¥ ë¬¸ë²• êµì •"""
    inputs = tokenizer.encode(text, return_tensors="pt", max_length=128, truncation=True)
    outputs = model.generate(inputs, max_length=128, num_beams=5)
    corrected = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return corrected

def correct_multiple_sentences(sentences: list[str]):
    """ì—¬ëŸ¬ ë¬¸ì¥ì„ ìˆœì°¨ì ìœ¼ë¡œ êµì •"""
    print("ğŸ“ ë¬¸ì¥ êµì • ê²°ê³¼:")
    print("=" * 40)
    for i, sentence in enumerate(sentences, 1):
        corrected = correct_sentence(sentence)
        print(f"{i}. âœï¸ ì›ë¬¸    : {sentence}")
        print(f"   âœ… êµì •ë³¸ : {corrected}")
        print("-" * 40)

# ì˜ˆì‹œ ì…ë ¥
if __name__ == "__main__":
    test_sentences = [
        "He go to school everyday.",
        "They is playing in the park.",
        "What time she wake up?",
        "The informations are incorrect.",
        "I has a apple."
    ]
    correct_multiple_sentences(test_sentences)